# 카프카 (Kafka)

## Topics and Paritions

- topic : 특정 데이터 스트림 (데이터베이스 table과 비슷함)
- partitions : topic의 구성 요소
  - 파티션 내부에서는 순서가 보장된다.
  - 파티션 내에서 각 메시지에 대한 offset을 가진다.
  - 기본적으로 1주일동안 저장되어 있다가 삭제된다.
  - 데이터는 파티션에 랜덤하게 쓰여지지만, 동일한 키를 가지는 데이터는 동일한 파티션에 저장된다.
  - 토픽 하나에 여러 개의 파티션을 가질 수 있다.
- 카프카 클러스터는 여러개의 브로커(서버)로 구성된다.
- 각 브로커는 unique id로 구분된다.
- 특정 브로커에 연결되면, 클러스터에 있는 브로커 전체에 연결된다. (모든 데이터는 각각의 브로커에 분산되 있지만, 하나에 연결 시 전체로 연결된다.)
- 일반적으로 브로커는 3개로 하는 것이 좋다.



## Topic replication factor

일반적으로 replication factor 값은 2-3이 가장 좋다.



## Leader for Partition

하나의 브로커는 특정 파티션의 리더가 되고, 리더만 데이터를 받고 처리할 수 있다. 다른 브로커들은 빠른 속도로 리더로부터 데이터를 동기화한다.



## Producers

- 토픽에 데이터를 전달하는 역할
- 토픽명을 가지고 하나의 브로커에 메시지를 발행하면, 카프카가 자동으로 데이터가 저장될 브로커에 라우팅한다.
- 데이터는 자동으로 로드밸런싱 돼 partition에 랜덤하게 분산된다.



## Consumers

- 토픽에서 데이터를 읽어오는 역할
- 컨슈머는 특정 토픽명을 가지고 데이터를 pull
- 하나의 브로커에 커넥트 시, 데이터가 있는 브로커에서 자동으로 데이터를 가져온다.
- 파티션 간에는 병렬적으로 읽지만 파티션 내에서는 순서가 보장된다.



## Consumer groups

- 그룹 내에 각 컨슈머는 서로 다른 파티션의 데이터를 읽어온다.
- 파티션 수보다 컨슈머 수가 적어야 한다. (많으면 남은 컨슈머는 inactive)



## Consumer offsets

- 카프카는 컨슈머 그룹이 읽어간 offset 정보를 저장한다.
- 컨슈머가 카프카에서 받은 데이터를 처리하고 오프셋을 커밋한다.
- 도중에 컨슈머가 죽으면 해당 offset부터 다시 읽어올 수 있다.



## Zookeeper

분산 애플리케이션이 안정적인 서비스를 할 수 있도록 분산되어 있는 각 애플리케이션의 정보를 중앙에 집중하고 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공해준다.

![img](https://blog.kakaocdn.net/dn/qYybV/btq3N6qF0yS/EYItVRyYoJVjOIRI6x0y60/img.png)

서버 여러 대를 앙상블로 구성하고, 분산 애플리케이션들이 각각 클라이언트가 되어 주키퍼 서버들과 커넥션을 맺고 상태 정보 등을 주고 받는다. (이 때 Server가 주키퍼, client가 카프카)

상태 정보들은 주키퍼의 znode라고 불리는 곳에 key-value 형태로 저장하며, znode에 저장되는 것을 이용하여 분산 애플리케이션들은 서로 데이터를 주고 받게 된다. 

![img](https://blog.kakaocdn.net/dn/dpTmCq/btq3ONK89mm/jVo9XEhncskGjiAVlis8p0/img.png)

​                                                                                                                znode

- 각 znode는 데이터 변경 등에 대한 유효성 검사 등을 위해 버전 번호를 관리(데이터가 변동될 때마다 znode 버전 번호 증가)
- 주키퍼에 저장되는 데이터는 모두 메모리에 저장되어 처리량이 매우 크고 속도도 빠르다.

주키퍼는 신뢰성 있는 서비스를 위해 앙상블이라는 호스트 셋을 구성할 수 있다. 주키퍼는 과반수 방식에 따라 살아 있는 노드 수가 과반 수 이상이면 지속적인 서비스가 가능하다.



