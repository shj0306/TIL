# 분산형 공유 변수

스파크의 저수준 API에는 RDD 외에도 분산형 공유 변수가 있습니다.

분산형 공유 변수에는 브로드캐스트 변수와 어큐뮬레이터라는 두 개의 타입이 존재합니다. 클러스터에서 실행할 때 특별한 속성을 가진 사용자 정의 함수에서 이 변수를 사용할 수 있습니다. 특히 **어큐뮬레이터**를 사용하면 모든 태스크의 데이터를 공유 결과에 추가할 수 있습니다.

반면 **브로드캐스트 변수**를 사용하면 모든 워커 노드에 큰 값을 저장하므로 재전송 없이 많은 스파크 액션에서 재사용할 수 있습니다.

## 1. 브로드캐스트 변수

불변값을 클로저 함수의 변수로 캡슐화하지 않고 클러스터에서 효율적으로 공유하는 방법을 제공합니다. 

브로드캐스트 변수는 모든 태스크마다 직렬화하지 않고 클러스터의 모든 머신에 캐시하는 불변성 공유 변수입니다. 익스큐터 메모리 크기에 맞는 조회용 테이블을 전달하고 함수에서 사용하는 것이 대표적인 예입니다.

```scala
val supplementalData = Map("Spark" -> 1000, "Definitive" -> 200, "Big" -> -300, "Simple" -> 100)
```

이 구조체를 스파크에 브로드캐스트할 수 있으며 suppBroadcast 변수를 이용해 참조합니다. 이 값은 불변성이며 액션을 실행할 때 클러스터의 모든 노드에 지연 처리 방식으로 복제됩니다.

```scala
val suppBroadcast = spark.sparkContext.broadcast(supplementalData)
```

suppBroadcast 변수의 value 메서드를 사용해 위 예제에서 브로드캐스트된 supplementalData 값을 참조할 수 있습니다. value 메서드는 직렬화된 함수에서 브로드캐스트된 데이터를 직렬화하지 않아도 접근할 수 있습니다. 스파크는 브로드캐스트 기능을 이용해 데이터를 보다 효율적으로 전송하므로 직렬화와 역직렬화에 대한 부하를 크게 줄일 수 있습니다.

```scala
suppBroadcast.value
```

이제 브로드캐스트된 데이터를 사용해 RDD를 변환할 수 있습니다. 다음 예제는 맵 연산의 처리 과정에 따라 키-값 쌍 데이터를 생성합니다.

```scala
words.map(word => (word, suppBroadcast.value.getOrElse(word, 0)))
     .sortBy(wordPair => wordPair._2)
     .collect()

//getorElse(word, val) : word값이 있다면 해당 값을 넣고 없다면 val를 넣는다.
```

브로드캐스트 변수를 사용한 방식이 클로저에 담아 전달하는 방식보다 훨씬 효율적입니다. 물론 데이터의 총량과 익스큐터의 수에 따라 다를 수 있으며, 아주 작은 데이터를 작은 클러스터에 돌린다면 큰 차이가 나지 않을 수 있습니다.

브로드캐스트 변수에 작은 크기의 딕셔너리 타입을 사용한다면 큰 부하가 발생하지 않습니다. 하지만 큰 크기의 데이터를 사용하는 경우라면 전체 태스크에서 데이터를 직렬화하는 데 발생하는 부하가 매우 커질 수 있습니다.

## 2. 어큐뮬레이터

어큐뮬레이터는 스파크의 두 번째 공유 변수 타입입니다. 어큐뮬레이터는 트랜스포메이션 내부의 다양한 값을 갱신하는 데 사용합니다.

스파크 클러스터에서 로우 단위로 안전하게 값을 갱신할 수 있는 변경 가능한 변수를 제공합니다. 디버깅용이나 저수준 집계 생성용으로 사용할 수 있습니다.

예를 들어 파티션별로 특정 변수의 값을 추적하는 용도로 사용할 수 있으며, 시간이 흐를수록 더 유용하게 사용됩니다.

어큐뮬레이터는 병렬 처리 과정에서 효율적으로 사용할 수 있습니다. 스파크는 기본적으로 수치형 어큐뮬레이터를 지원하며 사용자 정의 어큐뮬레이터를 만들어 사용할 수 있습니다.

어큐뮬레이터 값은 액션을 처리하는 과정에서만 갱신됩니다. 스파크는 각 태스크에서 어큐뮬레이터를 한 번만 갱신하도록 제어합니다. 따라서 재시작한 태스크는 어큐뮬레이터 값을 갱신할 수 없습니다. 트랜스포메이션에서 태스크나 잡 스테이지를 재처리하는 경우 각 태스크의 갱신 작업이 두 번 이상 적용될 수 있습니다.

어큐뮬레이터가 RDD 처리 중에 갱신되면 RDD 연산이 실제로 수행된 시점, 즉 특정 RDD나 그 RDD의 부모 RDD에 액션을 실행하는 시점에 딱 한 번만 값을 갱신합니다. 따라서 map 함수 같은 지연 처리 형태의 트랜스포메이션에서 어큐뮬레이터 갱신 작업을 수행하는 경우 실제 실행 전까지는 어큐뮬레이터가 갱신되지 않습니다.

### 2-1. 기본 예제

항공운항 데이터셋에 사용자 정의 집계를 수행하면서 어큐뮬레이터를 실험해봅니다.

```scala
case class Flight(dest_country_name:String, origin_country_name:String, count:BigInt)

val flights = spark.read.parquet("/FileStore/tables/2010-summary.parquet").as[Flight]
```

출발지나 도착지가 중국인 항공편의 수를 구하는 어큐뮬레이터를 생성합니다. 이런 집계는 SQL로 처리할 수 있습니다.

```scala
import org.apache.spark.util.LongAccumulator

val accChina = new LongAccumulator
val accChina2 = spark.sparkContext.longAccumulator("China")

spark.sparkContext.register(accChina, "China")
```

함수의 파라미터로 문자열값을 전달하거나 register 함수의 두 번째 파라미터를 사용해 이름을 지정할 수 있습니다.

```scala
def accChinaFunc(flight_row : Flight) = {
  val destination = flight_row.dest_country_name
  val origin = flight_row.origin_country_name
  
  if (destination == "China") {
    accChina.add(flight_row.count.toLong)
  }
  if (origin == "China") {
    accChina.add(flight_row.count.toLong)
  }
}
```

이제 foreach 메서드를 사용해 항공운항 데이터셋의 전체 로우를 처리해봅니다. 이유는 foreach 메서드가 액션이고, 스파크는 액션에서만 어큐뮬레이터의 실행을 보장하기 때문입니다. foreach 메서드는 입력 데이터프레임의 매 로우마다 함수를 한 번씩 적용해 어큐뮬레이터 값을 증가시킵니다.

```scala
//어큐뮬레이터 값을 확인하려면 value 메서드를 사용하면 됩니다.
accChina.value // 953
```

### 2-2. 사용자 정의 어큐뮬레이터

어큐뮬레이터를 직접 정의하려면 AccumulatorV2 클래스를 상속 받아야 합니다. 구현해야 하는 추상 메서드 몇 가지가 있습니다.

예제) 어큐뮬레이터에 짝수값만 더하는 예제

```scala
import scala.collection.mutable.ArrayBuffer
import org.apache.spark.util.AccumulatorV2

val arr = ArrayBuffer[BigInt]()

class EvenAccumulator extends AccumulatorV2[BigInt, BigInt] {
  private var num:BigInt = 0
  def reset(): Unit = {
    this.num = 0
  }
  def add(intValue: BigInt): Unit = {
    if (intValue % 2 == 0) {
      this.num += intValue
    }
  }
  def merge(other: AccumulatorV2[BigInt, BigInt]) : Unit = {
    this.num += other.value
  }
  
  def value():BigInt = {
    this.num
  }
  def copy():AccumulatorV2[BigInt, BigInt] = {
    new EvenAccumulator
  }
  def isZero():Boolean = {
    this.num == 0
  }
}

val acc = new EvenAccumulator
val newAcc = sc.register(acc, "evenAcc")

acc.value // 0
flights.foreach(flight_row => acc.add(flight_row.count))
acc.value // 31390
```

