# 조인 / 데이터소스

## 조인

- 스파크는 서로 다른 데이터를 조합할 수 있으므로 데이터를 처리할 때 기업의 여러 데이터 소스를 활용할 수 있습니다.

### 조인 표현식

- 스파크는 왼쪽과 오른쪽 데이터셋에 있는 하나 이상의 키값을 비교하고 왼쪽 데이터셋과 오른쪽 데이터셋의 결합 여부를 결정하는 조인 표현식의 평가 결과에 따라 두 개의 데이터셋을 조인합니다.
- 가장 많이 사용되는 조인 표현식은 왼쪽과 오른쪽 데이터셋에 지정된 키가 동일한 지 비교하는 동등 조인입니다. 키가 일치하면 왼쪽과 오른쪽 데이터셋을 결합합니다.
- 동등 조인뿐만 아니라 더 복잡한 조인 정책도 지원하고, 복합 데이터 타입을 조인에 사용할 수도 있습니다.

### 조인 타입

- 내부 조인 (inner join) : 왼쪽과 오른쪽 데이터셋에 키가 있는 로우를 유지 (교집합)
- 외부 조인 (outer join) : 왼쪽이나 오른쪽 데이터셋에 키가 있는 로우를 유지 (합집합)
- 왼쪽 외부 조인 (left outer join) : 왼쪽 데이터셋에 키가 있는 로우를 유지
- 오른쪽 외부 조인 (right outer join) : 오른쪽 데이터셋에 키가 있는 로우를 유지
- 왼쪽 세미 조인 (left semi join) : 왼쪽 데이터셋의 키가 오른쪽 데이터셋에 있는 경우에는 키가 일치하는 왼쪽 데이터셋만 유지
- 왼쪽 안티 조인 (left anti join) : 왼쪽 데이터셋의 키가 오른쪽 데이터셋에 없는 경우에는 키가 일치하지 않는 왼쪽 데이터셋만 유지
- 자연 조인 (natural join) : 두 데이터셋에서 동일한 이름을 가진 컬럼을 암시적으로 결합하는 조인
- 교차 조인 (cross join) 또는 카테시안 조인(Cartesian join) : 왼쪽 데이터셋의 모든 로우와 오른쪽 데이터셋의 모든 로우를 조합

### 내부 조인

-  예제) graduateProgram 데이터프레임과 person 데이터프레임을 조인해 새로운 데이터프레임을 만든다.

  ```scala
  val joinExpression = person.col("graduate_program") === graduateProgram.col("id")
  ```

- join 메서드의 joinType파라미터로 조인 타입을 명확하게 지정할 수 있습니다.

  ```scala
  val joinType = "inner"
  
  person.join(graduateProgram, joinExpression, joinType).show()
  
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  | id|            name|graduate_program|   spark_status| id| degree|          department|     school|
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  |  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|
  |  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  |  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  ```

### 외부 조인

- 데이터프레임이나 테이블에 존재하는 키를 평가하여 참이나 거짓으로 평가한 로우를 조인합니다.

- 왼쪽이나 오른쪽 데이터프레임에 일치하는 로우가 없다면 해당 위치에 null을 삽입합니다.

  ```scala
  val joinType = "outer"
  
  person.join(graduateProgram, joinExpression, joinType).show()
  +----+----------------+----------------+---------------+---+-------+--------------------+-----------+
  |  id|            name|graduate_program|   spark_status| id| degree|          department|     school|
  +----+----------------+----------------+---------------+---+-------+--------------------+-----------+
  |   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|
  |   1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  |   2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  |null|            null|            null|           null|  2|Masters|                EECS|UC Berkeley|
  +----+----------------+----------------+---------------+---+-------+--------------------+-----------+
  ```

### 왼쪽 외부 조인

- 왼쪽 데이터프레임의 모든 로우와 왼쪽 데이터프레임과 일치하는 오른쪽 데이터프레임의 로우를 함께 포함합니다. 오른쪽 데이터프레임에 일치하는 로우가 없다면 null

  ```scala
  val joinType = "left_outer"
  graduateProgram.join(person, joinExpression, joinType).show()
  
  +---+-------+--------------------+-----------+----+----------------+----------------+---------------+
  | id| degree|          department|     school|  id|            name|graduate_program|   spark_status|
  +---+-------+--------------------+-----------+----+----------------+----------------+---------------+
  |  0|Masters|School of Informa...|UC Berkeley|   0|   Bill Chambers|               0|          [100]|
  |  2|Masters|                EECS|UC Berkeley|null|            null|            null|           null|
  |  1|  Ph.D.|                EECS|UC Berkeley|   2|Michael Armbrust|               1|     [250, 100]|
  |  1|  Ph.D.|                EECS|UC Berkeley|   1|   Matei Zaharia|               1|[500, 250, 100]|
  +---+-------+--------------------+-----------+----+----------------+----------------+---------------+
  ```



### 왼쪽 세미 조인

<img src="https://mblogthumb-phinf.pstatic.net/MjAyMDA3MjhfMjE0/MDAxNTk1OTE0ODU5MzU4.WbHmtRKIKWzl6Om7NwN2cV279rcVHyenWQrYeQiSo2Yg.jwkH52cTPUTh0n2j5dV1y6uJ6jFIgo2Dvk6kwdFQhyog.PNG.jevida/1.png?type=w800" alt="img" style="zoom:80%;" />

- 두 번째 데이터프레임의 어떤 값도 결과에 포함하지 않습니다.

- 왼쪽 세미 조인은 기존 조인 기능과 달리 데이터프레임의 filter 정도로 볼 수 있습니다.

  ```scala
  val joinType = "left_semi"
  graduateProgram.join(person, joinExpression, joinType).show()
  
  +---+-------+--------------------+-----------+
  | id| degree|          department|     school|
  +---+-------+--------------------+-----------+
  |  0|Masters|School of Informa...|UC Berkeley|
  |  1|  Ph.D.|                EECS|UC Berkeley|
  +---+-------+--------------------+-----------+
  ```

### 왼쪽 안티 조인

- 왼쪽 세미 조인의 반대 개념입니다.

- 두 번째 데이터프레임에서 관련된 키를 찾을 수 없는 로우만 결과에 포함합니다.

- 안티 조인은 SQL의 NOT IN같은 스타일의 필터로 볼 수 있습니다.

  ```scala
  val joinType = "left_anti"
  graduateProgram.join(person, joinExpression, joinType).show()
  +---+-------+----------+-----------+
  | id| degree|department|     school|
  +---+-------+----------+-----------+
  |  2|Masters|      EECS|UC Berkeley|
  +---+-------+----------+-----------+
  ```

### 자연 조인

- 조인하려는 컬럼을 암시적으로 추정합니다. 즉 일치하는 컬럼을 찾고 그 결과를 반환합니다.

### 교차 조인

- 조건절을 기술하지 않은 내부 조인을 의미합니다.

- 1000개의 로우가 존재하는 두개의 데이터프레임이 교차 조인을 하면 1000000개의 로우를 갖는 데이터프레임을 생성합니다.

- 따라서 반드시 키워드를 이용해 교차 조인을 수행한다는 것을 명시적으로 선언해야 합니다.

  ```scala
  person.crossJoin(graduateProgram).show()
  
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  | id|            name|graduate_program|   spark_status| id| degree|          department|     school|
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  |  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|
  |  1|   Matei Zaharia|               1|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|
  |  2|Michael Armbrust|               1|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|
  |  0|   Bill Chambers|               0|          [100]|  2|Masters|                EECS|UC Berkeley|
  |  1|   Matei Zaharia|               1|[500, 250, 100]|  2|Masters|                EECS|UC Berkeley|
  |  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|
  |  0|   Bill Chambers|               0|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|
  |  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  |  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|
  +---+----------------+----------------+---------------+---+-------+--------------------+-----------+
  ```

- 교차조인은 정말로 필요한 경우에만 사용해야 하고, 명시적으로 교차조인을 정의해야 합니다.



### 조인 사용시 문제점

1. 복합 데이터 타입의 조인

   ```scala
   import org.apache.spark.sql.functions.expr
   
   person.withColumnRenamed("id", "personId")
     .join(sparkStatus, expr("array_contains(spark_status, id)")).show()
   
   +--------+----------------+----------------+---------------+---+--------------+
   |personId|            name|graduate_program|   spark_status| id|        status|
   +--------+----------------+----------------+---------------+---+--------------+
   |       0|   Bill Chambers|               0|          [100]|100|   Contributor|
   |       1|   Matei Zaharia|               1|[500, 250, 100]|500|Vice President|
   |       1|   Matei Zaharia|               1|[500, 250, 100]|250|    PMC Member|
   |       1|   Matei Zaharia|               1|[500, 250, 100]|100|   Contributor|
   |       2|Michael Armbrust|               1|     [250, 100]|250|    PMC Member|
   |       2|Michael Armbrust|               1|     [250, 100]|100|   Contributor|
   +--------+----------------+----------------+---------------+---+--------------+
   ```

2. 중복 컬럼명 처리

   - 데이터 프레임의 각 컬럼은 스파크 sql 엔진인 카탈리스트 내에 고유 id가 있습니다.

     고유 id는 직접 참조할 수 있는 값이 아니기 때문에 중복된 컬럼명이 있는 데이터프레임을 사용할 때 특정 컬럼을 참조하기 매우 어렵습니다.

     ```scala
     // 잘못된 데이터 셋 생성
     val gradProgramDupe = graduateProgram.withColumnRenamed("id", "graduate_program")
     val joinExpr = gradProgramDupe.col("graduate_program") === person.col("graduate_program")
     
     person.join(gradProgramDupe, joinExpr).show()
     +---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+
     | id|            name|graduate_program|   spark_status|graduate_program| degree|          department|     school|
     +---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+
     |  0|   Bill Chambers|               0|          [100]|               0|Masters|School of Informa...|UC Berkeley|
     |  2|Michael Armbrust|               1|     [250, 100]|               1|  Ph.D.|                EECS|UC Berkeley|
     |  1|   Matei Zaharia|               1|[500, 250, 100]|               1|  Ph.D.|                EECS|UC Berkeley|
     +---+----------------+----------------+---------------+----------------+-------+--------------------+-----------+
     ```

     graduate_program 컬럼으로 조인을 수행했음에도 두 개의 graduate_program이 존재하게 되고, 이러면 컬럼 중 하나를 참조할 때 오류가 발생하게 됩니다.

   - 해결 방법 1: 다른 조인 표현식 사용

     - 불리언 형태의 조인 표현식을 문자열이나 시퀀스 형태로 바꾸면 해결 할 수 있습니다.

       ```scala
       person.join(gradProgramDupe, "graduate_program").select("graduate_program").show()
       
       +----------------+
       |graduate_program|
       +----------------+
       |               0|
       |               1|
       |               1|
       +----------------+
       ```

   - 해결 방법 2: 조인 후 컬럼 제거

     ```scala
     person.join(gradProgramDupe, joinExpr).drop(person.col("graduate_program")).select("graduate_program").show()
     
     val joinExpr = person.col("graduate_program") === graduateProgram.col("id")
     person.join(graduateProgram, joinExpr).drop(graduateProgram.col("id")).show()
     ```

     - 스파크는 명시적으로 참조된 컬럼을 검증할 필요가 없으므로 스파크 코드 분석 단계를 통과합니다. col 메서드를 사용함으로써 컬럼 고유 id로 해당 컬럼을 암시적으로 지정할 수 있습니다.

   - 해결 방법 3: 조인 전 컬럼명 변경

     ```scala
     val gradProgram3 = graduateProgram.withColumnRenamed("id", "grad_id")
     val joinExpr = person.col("graduate_program") === gradProgram3.col("grad_id")
     person.join(gradProgram3, joinExpr).show()
     
     +---+----------------+----------------+---------------+-------+-------+--------------------+-----------+
     | id|            name|graduate_program|   spark_status|grad_id| degree|          department|     school|
     +---+----------------+----------------+---------------+-------+-------+--------------------+-----------+
     |  0|   Bill Chambers|               0|          [100]|      0|Masters|School of Informa...|UC Berkeley|
     |  2|Michael Armbrust|               1|     [250, 100]|      1|  Ph.D.|                EECS|UC Berkeley|
     |  1|   Matei Zaharia|               1|[500, 250, 100]|      1|  Ph.D.|                EECS|UC Berkeley|
     +---+----------------+----------------+---------------+-------+-------+--------------------+-----------+
     ```

### 스파크의 조인 수행 방식

- 노드 간 네트워크 통신 전략
- 노드별 연산 전략

### 네트워크 통신 전략

스파크는 조인 시 두가지 클러스터 통신 방식을 활용합니다.

1. 셔플 조인

2. 브로드 캐스트 조인

- 큰 테이블과 큰 테이블 조인

  - 하나의 큰 테이블과 다른 큰 테이블이 조인하면 셔플 조인이 발생합니다.
  - 셔플 조인은 전체 노드 간 통신이 발생합니다. 그리고 조인에 사용한 특정 키나 키 집합을 어떤 노드가 가졌는지에 따라 해당 노드와 데이터를 공유합니다.
  - 이런 방식 때문에 네트워크는 복잡해지고 자원 소모도 심합니다.

- 큰 테이블과 작은 테이블 조인

  - 테이블이 단일 워커 노드의 메모리 크기에 적합할 정도로 작은 경우 조인 연산을 최적화 할 수 있습니다.

  - 이런 경우 브로드캐스트 조인이 훨씬 효율적입니다.  이 방법은 작은 데이터프레임을 클러스터 전체 워커 노드에 복제하는 것을 의미합니다.

  - 이러면 자원을 많이 사용할 것처럼 보이지만 조인 프로세스 내내 전체 노드가 통신하는 현상을 방지할 수 있습니다. 시작 시 단 한번만 복제가 수행되며 그 이후부터는 개별 워커가 다른 워커 노드를 기다리거나 통신할 필요 없이 작업을 수행 할 수 있습니다.

  - 브로드 캐스트 조인도 마찬가지로 노드간 대규모 통신이 발생하지만 그 이후로는 노드 사이에 추가적인 통신이 발생하지 않습니다. 따라서 모든 단일 노드에서 개별적으로 조인이 수행되므로 CPU가 가장 큰 병목 구간이 됩니다.

  - 예제) 스파크가 자동으로 데이터셋을 브로드캐스트 조인으로 설정

    ```scala
    val joinExpr = person.col("graduate_program") === graduateProgram.col("id")
    person.join(graduateProgram, joinExpr).explain()
    
    == Physical Plan ==
    AdaptiveSparkPlan isFinalPlan=false
    +- BroadcastHashJoin [graduate_program#43], [id#62], Inner, BuildLeft, false
       :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[2, int, false] as bigint)),false), [id=#1529]
       :  +- LocalTableScan [id#41, name#42, graduate_program#43, spark_status#44]
       +- LocalTableScan [id#62, degree#63, department#64, school#65]
    
    ```

  - broadcast 함수에 작은 크기의 데이터프레임을 인수로 전달할 수 있습니다.

    ```scala
    import org.apache.spark.sql.functions.broadcast
    
    val joinExpr = person.col("graduate_program") === graduateProgram.col("id")
    person.join(broadcast(graduateProgram), joinExpr).explain()
    ```

  - 너무 큰 데이터를 브로드캐스트하면 고비용의 수집 연산이 발생하므로 드라이버 노드가 비정상적으로 종료될 수 있습니다.

- 아주 작은 테이블 간의 조인

  - 이 때는 스파크가 조인 방식을 결정하도록 내버려 두는 것이 베스트입니다.



## 정리

조인 전에 데이터를 적절하게 분할하면 셔플이 계획되어 있더라도 동일한 머신에 두 데이터프레임의 데이터가 있을 수 있습니다. 따라서 셔플을 피할 수 있고, 훨씬 더 효율적으로 실행할 수 있습니다.  그렇기 때문에 일부 데이터를 실험용으로 사전에 분할해 조인 수행 시 성능이 향상되는 지를 테스트 해보면 좋습니다.

