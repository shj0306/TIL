# 스파크 애플리케이션 개발하기

## 1. 스파크 애플리케이션 작성하기

스파크 애플리케이션은 스파크 클러스터와 사용자 코드 두가지 조합으로 구성됩니다. 예제에서는 클러스터 모드를 로컬 모드로 설정하고, 사전에 정의된 애플리케이션을 사용자 코드로 사용합니다.

## 1-1. 스칼라 기반 앱

스파크 애플리케이션은 두 가지 자바 가상 머신 기반의 빌드 도구인 sbt나 아파치 메이븐을 이용해 빌드할 수 있습니다. 각각 장단점이 있지만 sbt를 사용하는 것이 더 쉽습니다. sbt는 sbt웹사이트에서 내려받을 수 있으며 설치와 사용법을 배울 수 있습니다. 메이븐 역시 사이트에서 설치할 수 있습니다.

스칼라 애플리케이션에 sbt 빌드 환경을 구성하려면 패키지 정보를 관리하기 위해 build.sbt 파일을 정의해야 합니다. 

### build.sbt 파일에 포함되어야 할 항목

- 프로젝트 메타데이터
- 라이브러리 의존성을 관리하는 장소
- 라이브러리에 포함된 의존성 정보

 #### 해당 책이 스파크 2버전이라 현재 에러가 발생 => 현재 해결방법 찾는 중



## 1-2. 파이썬 애플리케이션 작성하기

```python
from __future__ import print_function

if __name__ == '__main__':

    from pyspark.sql import SparkSession

    spark = SparkSession.builder \
        .master("local") \
        .appName("Word Count") \
        .config("spark.some.config.option", "some-value") \
        .getOrCreate()
        
    print(spark.range(5000).where("id > 500").selectExpr("sum(id)").collect())
```

스파크에는 빌드 개념이 없으며 pyspark 애플리케이션은 파이썬 스크립트에 지나지 않기 때문에 클러스터에서 스크립트를 실행하기만 하면 됩니다.

코드를 실행하려면 SparkSession을 생성하는 실행 가능한 스크립트 파일을 만들어야 합니다.

### 애플리케이션 실행하기

```shell
$SPARK_HOME/bin/spark-submit --master local pyspark_template/main.py
```

