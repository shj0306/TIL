# 클러스터에서 스파크 실행

## 1. 스파크 애플리케이션의 아키텍처와 컴포넌트

- 스파크 드라이버

  스파크 드라이버는 스파크 애플리케이션의 운전자 역할을 하는 프로세스입니다. 드라이버는 스파크 애플리케이션의 실행을 제어하고 스파크 클러스터의 모든 상태 정보를 유지합니다. 또한 물리적 컴퓨팅 자원 확보와 익스큐터 실행을 위해 클러스터 매니저와 통신할 수 있어야합니다.

- 스파크 익스큐터

  스파크 익스큐터는 스파크 드라이버가 할당한 태스크를 수행하는 프로세스입니다. 익스큐터는 드라이버가 할당한 태스크를 받아 실행하고 태스크의 상태와 결과를 드라이버에 보고합니다. 모든 스파크 애플리케이션은 개별 익스큐터 프로세스를 사용합니다.

- 클러스터 매니저

  스파크 드라이버와 익스큐터를 허공에 띄울 수 없기 때문에 클러스터 매니저가 필요합니다.  클러스터 매니저는 스파크 애플리케이션을 실행할 클러스터 머신을 유지합니다. 

스파크 애플리케이션을 실행할 때가 되면 클러스터 매니저에 자원 할당을 요청합니다. 사용자 애플리케이션의 설정에 따라 스파크 드라이버를 실행할 자원을 포함해 요청하거나 스파크 애플리케이션 실행을 위한 익스큐터 자원을 요청할 수도 있습니다. 스파크 애플리케이션의 실행 과정에서 클러스터 매니저는 애플리케이션이 실행되는 머신을 관리합니다.

### 스파크가 지원하는 클러스터 매니저

- standalone 클러스터 매니저
- 아파치 메소스
- 하둡 Yarn

### 1.1 실행 모드

실행 모드는 애플리케이션을 실행할 때 요청한 자원의 물리적인 위치를 결정합니다.

- 클러스터 모드
- 클라이언트 모드
- 로컬 모드

#### 클러스터 모드

컴파일된 jar 파일이나 파이썬 스크립트 또는 R 스크립트를 클러스터 매니저에 전달해야 합니다. 클러스터 매니저는 파일을 받은 다음 워커 노드에 드라이버와 익스큐터 프로세스를 실행합니다. 

#### 클라이언트 모드

애플리케이션을 제출한 클라이언트 머신에 스파크 드라이버가 위치한다는 것을 제외하면 클러스터 모드와 비슷합니다.

클라이언트 모드는 스파크 드라이버 프로세스를 유지하며 클러스터 매니저는 익스큐터 프로세스를 유지합니다. 드라이버는 클러스터 외부 머신에서 실행되며 나머지 워커는 클러스터에 위치하는 것을 알 수 있습니다.

#### 로컬 모드

로컬 모드는 모든 스파크 애플리케이션을 단일 머신에서 실행합니다. 애플리케이션의 병렬 처리를 위해 단일 머신의 스레드를 활용합니다. 이 모드는 스파크를 학습하거나 애플리케이션 테스트 그리고 개발 중인 애플리케이션을 반복적으로 실험하는 용도로 사용됩니다.

## 2. 스파크 애플리케이션 lifetime (스파크 외부)

하나의 드라이버 노드와 세 개의 워커 노드로 구성된 총 네 대의 클러스터가 실행되도 있다고 가정합니다.

### 2-1. 클라이언트 요청

첫 단계는 스파크 애플리케이션을 제출하는 겁니다. 스파크 애플리케이션을 제출하는 시점에 로컬 머신에서 코드가 실행되어 클러스터 드라이버 노드에 요청됩니다. 이 과정에서 스파크 드라이버 프로세스의 자원을 함께 요청합니다. 클러스터 매니저는 이 요청을 받아들이고 클러스터 노드 중 하나에 드라이버 프로세스를 실행합니다. 

스파크 애플리케이션을 제출하기 위해 터미널에 다음과 같은 명령을 실행합니다.

```shell
./bin/spark-submit \
--class <main-class> \
--master <master-url> \
--deploy-mode cluster \
--conf <key>=<value> \
....
<application.jar> \
[application-arguments]
```

### 2-2. 시작

드라이버 프로세스가 클러스터에 배치되었으므로 사용자 코드를 실행할 차례입니다. 사요아 코드에는 스파크 클러스터를 초기화하는 SparkSession이 포함되어야 합니다. SparkSession은 클러스터 매니저와 통신해 스파크 익스큐터 프로세스의 실행을 요청합니다. 사용자는 spark-submit을 실행할 때 사용하는 명령행 인수로 익스큐터 수와 설정값을 지정할 수 있습니다.

클러스터 매니저는 익스큐터 프로세스를 시작하고 결과를 응답받아 익스큐터의 위치와 관련 정보를 드라이버 프로세스로 전송합니다. 모든 작업이 정상적으로 완료되면 스파크 클러스터가 완성됩니다.

### 2-3. 실행

스파크 클러스터가 생성되면 코드를 실행합니다. 드라이버와 워커는 코드를 실행하고 데이터를 이동하는 과정에서 서로 통신합니다. 드라이버는 각 워커에 태스크를 할당합니다. 태스크를 할당받은 워커는 태스크의 상태와 성공/실패 여부를 드리이버에 전송합니다.

### 2-4. 완료

스파크 애플리케이션의 실행이 완료되면 드라이버 프로세스가 성공이나 실패 중 하나의 상태로 종료됩니다. 그 다음 클러스터 매니저는 드라이버가 속한 스파크 클러스터의 모든 익스큐터를 종료시킵니다. 이 시점에 성공/실패 여부를 확인할 수 있습니다.



## 3. 스파크 애플리케이션의 lifetime(스파크 내부)

### 3-1. SparkSession

모든 스파크 애플리케이션은 가장 먼저 SparkSession을 생성합니다.

SparkSession의 빌더 메서드를 사용해 생성하는 것이 좋습니다. 이 방식을 사용하면 스파크와 스파크SQL 컨텍스트를 new Sparkcontext 패턴을 사용해서 만드는 것보다 안전하게 생성할 수 있습니다. 그리고 스파크 애플리케이션에서 다수의 라이브러리가 세션을 생성하려는 상황에서 컨텍스트 충돌을 방지할 수 있습니다.

SparkSession을 생성하면 스파크 코드를 실행할 수 있습니다. SparkSession을 사용해 모든 저수준 API, 기존 컨텍스트 그리고 관련 설정 정보에 접근할 수 있습니다.

**SparkContext**

SparkSession의 SparkContext는 스파크 클러스터에 대한 연결을 나타냅니다. SparkContext를 이용해 RDD같은 스파크의 저수준 API를 사용할 수 있습니다. 

대부분 SparkSession으로 SparkContext에 접근할 수 있으므로 명시적으로 SparkContext를 초기화할 필요는 없습니다. 직접 초기화할 땐 getOrcreate 메서드를 사용하는 겁니다.

### 3-2. 논리적 명령

**논리적 명령을 물리적 실행 계획으로 변환하기**

```python
df1 = spark.range(2, 10000000, 2)
df2 = spark.range(2, 10000000, 4)
step1 = df1.repartition(5)
step12 = df2.repartition(6)
step2 = step1.selectExpr("id * 5 as id")
step3 = step2.join(step12, ["id"])
step4 = step3.selectExpr("sum(id)")

step4.collect() # 2500000000000
```

### 3-3. 스파크 잡

보통 액션 하나당 하나의 스파크 잡이 생성되며 액션은 항상 결과를 반환합니다. 스파크 잡은 일련의 스테이지로 나뉘며 스테이지 수는 셔플 작업이 얼마나 많이 발생하는지에 따라 달라집니다.

### 3-4. 스테이지

스파크의 스테이지는 다수의 머신에서 동일한 연산을 수행하는 태스크의 그룹을 나타냅니다. 스파크는 가능한 많은 태스크를 동일한 스테이지로 묶으려 노력합니다. 셔플 작업이 일어난 다음에는 반드시 새로운 스테이지를 시작합니다. 셔플은 데이터의 물리적 재분배 과정입니다. 파티션을 재분배하는 과정은 데이터를 이동시키는 작업이므로 익스큐터 간의 조정이 필요합니다. 스파크는 셔플이 끝난 다음 새로운 스테이지를 시작하며 최종 결과를 계산하기 위해 스테이지 실행 순서를 계속 추적합니다.

여러 요인에 의해 영향을 받을 수 있지만, 경험적으로 보면 클러스터의 익스큐터 수보다 파티션 수를 더 크게 지정하는 것이 더 좋습니다. 로컬 머신에서 코드를 실행하는 경우 병렬로 처리할 수 있는 태스크 수가 제한적이므로 이 값을 작게 설정해야 합니다. 이 설정은 더 많은 익스큐터 코어를 사용할 수 있는 클러스터 환경을 위한 기본값입니다. 최종 스테이지에서는 드라이버로 결과를 전송하기 전에 파티션마다 개별적으로 수행된 결과를 단일 파티션으로 모으는 작업을 수행합니다.

### 3-5. 태스크

스파크의 스테이지는 태스크로 구성됩니다. 각 태스크는 단일 익스큐터에서 실행할 데이터의 블록과 다수의 트랜스포메이션 조합으로 볼 수 있습니다. 만약 데이터셋이 거대한 하나의 파티션인 경우 하나의 태스크만 생성됩니다. 만약 1000개의 작은 파티션으로 구성되어 있다면 1000개의 태스크를 만들어 병렬로 실행할 수 있습니다. 즉 태스크는 데이터 단위에 적용되는 연산 단위를 의미합니다. 파티션 수를 늘리면 더 높은 병렬성을 얻을 수 있습니다.

## 3-4. 세부 실행 과정

스파크의 스테이지와 태스크는 중요한 특성을 가지고 있습니다.

1. 스파크는 map 연산 후 다른 map 연산이 이어진다면 함께 실행할 수 있도록 스테이지와 태스크를 자동으로 연결합니다.
2. 스파크는 모든 셔플을 작업할 때 데이터를 안정적인 저장소에 저장하므로 여러 잡에서 재사용할 수 있습니다.

### 4-1. 파이프라이닝

파이프라이닝 기법은 노드 간의 데이터 이동없이 각 노드가 데이터를 직접 공급할 수 있는 연산만 모아 태스크의 단일 스테이지로 만듭니다. 

파이프라인으로 구성된 연산 작업은 단계벼로 메모리나 디스크에 중간 결과를 기록하는 방식보다 훨씬 처리 속도가 빠릅니다.

### 4-2. 셔플 결과 저장

스파크가 reduce-by-key 연산 같이 노드 간 복제를 유발하는 연산을 실행하면 엔진에서 파이프라이닝을 수행하지 못하므로 네트워크 셔플이 발생합니다. 노드 간 복제를 유발하는 연산은 각 키에 대한 입력 데이터를 먼저 여러 노드로부터 복사합니다. 항상 데이터 전송이 필요한 소스 태스크를 먼저 수행하기 때문입니다. 그리고 소스 태스크의 스테이지가 실행되는 동안 셔플 파일을 로컬 디스크에 기록합니다. 그 다음 그룹화나 리듀스를 수행하는 스테이지가 시작됩니다. 이 스테이지에선 셔플 파일에서 레코드를 읽어 들인 다음 연산을 수행합니다. 



## 정리

스파크 애플리케이션을 클러스터에서 실행하면 어떤 일이 일어나는 지에 대해 알아보았습니다. 클러스터에서 실제로 실행되는 방식과 스파크 애플리케이션 내부에서 어떤 일이 일어나는 지 알 수 있었습니다.
